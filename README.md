# 🧠 Variable-Length Repeated Substring Detection Algorithms

_A Complete Instructional Course Generated by an LLM_

---

## 📘 Overview

This repository contains all instructional materials, code examples, and supporting artifacts for the course **“Variable-Length Repeated Substring Detection Algorithms.”**
The entire course was **generated by an LLM (Large Language Model)** using a structured instructional design framework to ensure clarity, depth, and pedagogical rigor.

The course explores multiple algorithmic strategies for detecting repeated substrings (or n-grams) of variable lengths within text data — from simple sliding windows to production-grade suffix arrays and streaming systems.

---

## 🏗️ Course Design Philosophy

This course was _not_ written by hand — it was **authored by an LLM under explicit meta-instructional constraints** to simulate how a human instructor would progressively teach algorithmic thinking.

The design emphasizes:

- **Concrete → Abstract progression:** always start from examples (“banana”) before introducing theory.
- **“Show failure before solution”:** demonstrate naive approaches and their limitations first.
- **Stepwise abstraction:** introduce one new concept per section.
- **Pair-programming style narration:** explanations simulate an expert thinking aloud.
- **Production awareness:** every algorithm is tied to real-world trade-offs.

---

## 🧩 Course Modules

| Module       | Title                              | Core Focus                                                    |
| :----------- | :--------------------------------- | :------------------------------------------------------------ |
| **0**        | _Prerequisites and Problem Setup_  | Foundational terms, motivating examples                       |
| **1**        | _Sliding Window Approach_          | Naive and parameterized n-gram counting                       |
| **2**        | _Suffix Array Method_              | Efficient substring analysis via sorting and LCP arrays       |
| **3**        | _Hash-Based Method_                | Rolling hash optimization for faster detection                |
| **4**        | _Streaming Approach_               | Memory-bounded and chunked file processing                    |
| **5**        | _Comparative Analysis & Selection_ | Benchmarking and algorithmic trade-offs                       |
| **6**        | _Extensions and Applications_      | Case studies: plagiarism, DNA, log analysis                   |
| **Appendix** | _Implementation Gallery_           | Full reference implementations, tests, and optimization notes |

For the detailed instructional sequence, see [`ZEN_toc.md`](./ZEN_toc.md).

---

## 🧮 Algorithms Covered

1. **Sliding Window (O(L×n))** — simplest, ideal for small data.
2. **Suffix Array (O(L log L))** — scalable, great for large repeated queries.
3. **Rolling Hash (Expected O(L×n))** — fast, pragmatic, widely used in text and DNA analysis.
4. **Streaming Counter (O(L))** — for data too large to fit in memory.

Each algorithm is presented in a _teaching-first, production-second_ manner:

- Start with a literal hand-traced example.
- Progress to explicit code.
- Then optimize and analyze complexity.
- Finally, explain _when and why_ to use it.

---

## 🧠 How to Use This Repository

### 1. **For Learners**

- Begin with **Module 0** and follow sequentially.
- Run each code cell manually — you’ll learn more by tracing.
- Compare algorithm outputs on the same input (e.g., `"banana"`).

### 2. **For Instructors**

- The outline (`ZEN_toc.md`) doubles as a _generation template_ — it can be reused with an LLM to regenerate or adapt the course for other domains.
- Each “LLM Generation Hint” acts as a structured _prompting scaffold_.

### 3. **For Developers**

- Explore `implementations/` for reference code.
- Each algorithm includes type hints, comments, and complexity notes.
- Run `tests/` to validate equivalence across methods.

---

## 🧑‍💻 Repository Structure

```
📂 variable-length-repeated-substring-course/
├── README.md                ← This file
├── ZEN_toc.md               ← Instructional design outline (LLM generation blueprint)
├── modules/
│   ├── 00_prerequisites/
│   ├── 01_sliding_window/
│   ├── 02_suffix_array/
│   ├── 03_hash_based/
│   ├── 04_streaming/
│   ├── 05_comparative_analysis/
│   └── 06_applications/
├── implementations/
│   ├── sliding_window.py
│   ├── suffix_array.py
│   ├── rolling_hash.py
│   ├── streaming_counter.py
│   └── benchmarks.py
├── tests/
│   ├── test_correctness.py
│   └── test_performance.py
└── data/
    └── sample_texts/
```

---

## 🧪 Requirements

- Python ≥ 3.9
- Dependencies: `numpy`, `pandas`, `matplotlib` (for analysis modules)

Install with:

```bash
pip install -r requirements.txt
```

---

## 🧭 Learning Outcomes

By the end of this course, learners will:

- Understand multiple strategies for repeated substring detection.
- Implement, optimize, and benchmark algorithms across datasets.
- Make informed trade-offs between time, memory, and maintainability.
- Recognize how professional engineers reason about algorithm choice.

---

## ⚙️ Meta-Generation Note

This course was **LLM-generated end-to-end** using the meta-prompt structure embedded in [`ZEN_toc.md`](./ZEN_toc.md).
The content was intentionally designed to test **pedagogical alignment and algorithmic reasoning capabilities** of language models.

If you reuse this outline, please cite:

> _“LLM-Generated Instructional Course Framework for Algorithmic Education” (ZEN Outline, 2025)._

---

## 🪴 License

All code and instructional content are released under the **MIT License**.
You are free to use, adapt, and redistribute with attribution.

---

## 💬 Acknowledgements

Special thanks to:

- The instructional design principles that inspired the **ZEN framework** — _“Build from concrete to abstract, failure to solution.”_
- The LLM that generated the entire curriculum.
