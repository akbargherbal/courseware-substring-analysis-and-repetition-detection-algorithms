<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>05-comparative-analysis-algorithm-selection</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <style>
        :root {
            --primary: #6366f1;
            --primary-dark: #4f46e5;
            --secondary: #8b5cf6;
            --bg-main: #0f172a;
            --bg-card: #1e293b;
            --bg-code: #0f172a;
            --text-primary: #f1f5f9;
            --text-secondary: #94a3b8;
            --border: #334155;
            --accent: #06b6d4;
            --success: #10b981;
        }
        
        * { margin: 0; padding: 0; box-sizing: border-box; }
        
        body { 
            font-family: 'Inter', -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif;
            line-height: 1.7; 
            color: var(--text-primary); 
            background: var(--bg-main);
        }
        
        .container { 
            max-width: 1200px; 
            margin: 0 auto; 
            padding: 20px; 
        }
        
        .home-btn { 
            position: fixed; 
            top: 20px; 
            right: 20px; 
            background: var(--accent);
            color: white; 
            width: 50px;
            height: 50px;
            border-radius: 50%;
            text-decoration: none; 
            z-index: 1000;
            box-shadow: 0 4px 20px rgba(6, 182, 212, 0.4);
            transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
            font-size: 24px;
            display: flex;
            align-items: center;
            justify-content: center;
        }
        
        .home-btn:hover { 
            background: #0891b2;
            transform: translateY(-2px);
            box-shadow: 0 8px 30px rgba(6, 182, 212, 0.5);
        }
        
        .breadcrumb { 
            background: var(--bg-card);
            padding: 12px 0; 
            margin-bottom: 24px; 
            font-size: 14px;
            border-radius: 8px;
            border: 1px solid var(--border);
        }
        
        .breadcrumb a { 
            color: var(--accent);
            text-decoration: none;
            transition: color 0.2s;
        }
        
        .breadcrumb a:hover { 
            color: var(--primary);
            text-decoration: underline;
        }
        
        .content { 
            background: var(--bg-card);
            padding: 3rem; 
            border-radius: 16px; 
            box-shadow: 0 4px 20px rgba(0, 0, 0, 0.3);
            border: 1px solid var(--border);
        }
        
        .file-list { 
            display: grid; 
            grid-template-columns: repeat(auto-fill, minmax(300px, 1fr)); 
            gap: 1.5rem; 
            margin: 2rem 0; 
        }
        
        .file-item { 
            padding: 1.5rem; 
            border: 1px solid var(--border);
            border-radius: 12px; 
            background: var(--bg-main);
            transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
            position: relative;
            overflow: hidden;
        }
        
        .file-item::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 3px;
            background: linear-gradient(90deg, var(--primary), var(--secondary));
            opacity: 0;
            transition: opacity 0.3s;
        }
        
        .file-item:hover { 
            transform: translateY(-4px); 
            box-shadow: 0 8px 30px rgba(99, 102, 241, 0.3);
            border-color: var(--primary);
        }
        
        .file-item:hover::before {
            opacity: 1;
        }
        
        .file-item a { 
            color: var(--text-primary);
            text-decoration: none; 
            font-weight: 600; 
            display: block;
            font-size: 1.1rem;
        }
        
        .file-item a:hover { 
            color: var(--primary);
        }
        
        .file-type { 
            font-size: 13px; 
            color: var(--text-secondary);
            margin-top: 8px; 
            font-weight: 500;
        }
        
        /* Code Blocks */
        pre { 
            background: var(--bg-code);
            padding: 1.5rem; 
            border-radius: 12px; 
            overflow-x: auto;
            border: 1px solid var(--border);
            margin: 1.5rem 0;
            box-shadow: 0 4px 10px rgba(0, 0, 0, 0.3);
        }
        
        pre code { 
            background: none;
            padding: 0;
            font-family: 'Fira Code', 'Consolas', monospace;
            font-size: 0.9em;
            line-height: 1.6;
        }
        
        /* Inline Code */
        code { 
            background: var(--bg-code);
            color: #8b5cf6;
            padding: 3px 8px; 
            border-radius: 6px; 
            font-size: 1.1em;
            font-family: 'Fira Code', 'Consolas', monospace;
            border: 1px solid var(--border);
        }
        
        /* Headings */
        h1, h2, h3, h4, h5, h6 { 
            color: var(--text-primary);
            margin: 2rem 0 1rem 0;
            font-weight: 700;
            letter-spacing: -0.5px;
        }
        
        h1 { 
            font-size: 2.5rem;
            background: linear-gradient(135deg, var(--primary), var(--secondary));
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
            border-bottom: 3px solid var(--primary);
            padding-bottom: 12px;
            margin-bottom: 1.5rem;
        }
        
        h2 { 
            font-size: 2rem;
            color: var(--primary);
            border-bottom: 2px solid var(--border);
            padding-bottom: 8px;
        }
        
        h3 { 
            font-size: 1.5rem;
            color: var(--accent);
        }
        
        /* Links */
        a { 
            color: var(--accent);
            transition: color 0.2s;
        }
        
        a:hover { 
            color: var(--primary);
        }
        
        /* Paragraphs */
        p {
            margin: 1rem 0;
            color: var(--text-secondary);
        }
        
        /* Lists */
        ul, ol {
            margin: 1rem 0;
            padding-left: 2rem;
            color: var(--text-secondary);
        }
        
        li {
            margin: 0.5rem 0;
        }
        
        /* Tables */
        table { 
            border-collapse: collapse;
            width: 100%;
            margin: 1.5rem 0;
            background: var(--bg-main);
            border-radius: 8px;
            overflow: hidden;
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.2);
        }
        
        th, td { 
            border: 1px solid var(--border);
            padding: 12px 16px;
            text-align: left;
        }
        
        th { 
            background: linear-gradient(135deg, var(--primary), var(--secondary));
            color: white;
            font-weight: 600;
        }
        
        tr:hover {
            background: var(--bg-card);
        }
        
        /* Blockquotes */
        blockquote {
            border-left: 4px solid var(--primary);
            padding: 1rem 1.5rem;
            margin: 1.5rem 0;
            background: var(--bg-main);
            border-radius: 0 8px 8px 0;
            color: var(--text-secondary);
            font-style: italic;
        }
        
        /* Horizontal Rule */
        hr {
            border: none;
            border-top: 2px solid var(--border);
            margin: 2rem 0;
        }
        
        .footer { 
            text-align: center; 
            padding: 2rem; 
            color: var(--text-secondary);
            border-top: 1px solid var(--border);
            margin-top: 3rem; 
            font-size: 14px;
        }
        
        /* Scrollbar */
        ::-webkit-scrollbar {
            width: 12px;
            height: 12px;
        }
        
        ::-webkit-scrollbar-track {
            background: var(--bg-main);
        }
        
        ::-webkit-scrollbar-thumb {
            background: var(--border);
            border-radius: 6px;
        }
        
        ::-webkit-scrollbar-thumb:hover {
            background: var(--primary);
        }
        
        @media (max-width: 768px) {
            .container { padding: 10px; }
            .file-list { grid-template-columns: 1fr; }
            .content { padding: 1.5rem; }
            h1 { font-size: 2rem; }
            h2 { font-size: 1.5rem; }
        }
    </style>
</head>
<body>
    <a href="./index.html" class="home-btn">üè†</a>
    <div class="container">
        <div class="breadcrumb">
            <div style="padding: 0 20px;">
                <a href="./index.html">üè† Home</a>
            </div>
        </div>
        <div class="content">
            <h1 id="module-5-comparative-analysis-algorithm-selection">Module 5: Comparative Analysis &amp; Algorithm Selection</h1>
<h2 id="benchmark-setup">Benchmark Setup</h2>
<h2 id="learning-objective">Learning Objective</h2>
<p>Design fair performance comparisons for our different substring finding algorithms.</p>
<h2 id="why-this-matters">Why This Matters</h2>
<p>So far, we've treated our four algorithms‚ÄîSliding Window, Suffix Array, Rolling Hash, and Streaming‚Äîas separate solutions. But in a real-world scenario, you have to choose <em>one</em>. Making the right choice depends on understanding their trade-offs, and that requires a fair, systematic way to measure their performance. This is called benchmarking. Getting this right is the foundation for making informed engineering decisions.</p>
<h2 id="discovery-phase">Discovery Phase</h2>
<p>Before we can compare our algorithms, we need three things:
1.  <strong>The Algorithms</strong>: Working implementations of the four approaches we've learned.
2.  <strong>The Data</strong>: A consistent set of text data to run them on, representing different scales.
3.  <strong>The Harness</strong>: A measurement tool to consistently track execution time and memory usage.</p>
<p>Let's build these components.</p>
<h3 id="step-1-representative-algorithm-implementations">Step 1: Representative Algorithm Implementations</h3>
<p>For this module, we'll use simplified but functionally representative versions of the algorithms from the previous modules. This keeps the focus on comparison rather than implementation details. Notice that each function is designed to find the most frequent 5-gram to give them a consistent task.</p>
<ul>
<li><strong>Sliding Window</strong>: The straightforward, brute-force approach from Module 1.</li>
<li><strong>Suffix Array</strong>: A simplified version that builds a suffix array and an LCP array to find repeats (Module 2). It's powerful but memory-intensive.</li>
<li><strong>Rolling Hash</strong>: The Rabin-Karp inspired approach from Module 3, which avoids re-hashing the entire window each time.</li>
<li><strong>Streaming</strong>: The generator-based, memory-efficient approach from Module 4.</li>
</ul>
<div class="codehilite"><pre><span></span><code><span class="c1"># --- Algorithm Implementations (Simplified for Benchmarking) ---</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">collections</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">tracemalloc</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">random</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">string</span>

<span class="c1"># --- ALGORITHM 1: SLIDING WINDOW (from Module 1) ---</span>
<span class="k">def</span><span class="w"> </span><span class="nf">find_repeats_sliding_window</span><span class="p">(</span><span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">n</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">collections</span><span class="o">.</span><span class="n">Counter</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Finds n-gram frequencies using a simple sliding window.&quot;&quot;&quot;</span>
    <span class="n">counts</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">Counter</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">)</span> <span class="o">-</span> <span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">ngram</span> <span class="o">=</span> <span class="n">text</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">n</span><span class="p">]</span>
        <span class="n">counts</span><span class="p">[</span><span class="n">ngram</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">counts</span>

<span class="c1"># --- ALGORITHM 2: SUFFIX ARRAY (from Module 2) ---</span>
<span class="k">def</span><span class="w"> </span><span class="nf">find_repeats_suffix_array</span><span class="p">(</span><span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">n</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">collections</span><span class="o">.</span><span class="n">Counter</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Finds n-gram frequencies using a suffix array and LCP array.&quot;&quot;&quot;</span>
    <span class="n">num_suffixes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="c1"># Step 1: Build the suffix array (tuples of suffix and original index)</span>
    <span class="c1"># In a real implementation, you&#39;d just store indices, but this is clearer.</span>
    <span class="n">suffixes</span> <span class="o">=</span> <span class="p">[(</span><span class="n">text</span><span class="p">[</span><span class="n">i</span><span class="p">:],</span> <span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_suffixes</span><span class="p">)]</span>

    <span class="c1"># Step 2: Sort the suffixes lexicographically</span>
    <span class="n">suffixes</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

    <span class="c1"># Step 3: Build LCP array (Longest Common Prefix)</span>
    <span class="c1"># This is a simplified LCP construction for clarity. Kasai&#39;s is faster.</span>
    <span class="n">lcp</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">num_suffixes</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_suffixes</span><span class="p">):</span>
        <span class="n">s1</span> <span class="o">=</span> <span class="n">suffixes</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">s2</span> <span class="o">=</span> <span class="n">suffixes</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">common_len</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">while</span> <span class="n">common_len</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">s1</span><span class="p">)</span> <span class="ow">and</span> <span class="n">common_len</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">s2</span><span class="p">)</span> <span class="ow">and</span> <span class="n">s1</span><span class="p">[</span><span class="n">common_len</span><span class="p">]</span> <span class="o">==</span> <span class="n">s2</span><span class="p">[</span><span class="n">common_len</span><span class="p">]:</span>
            <span class="n">common_len</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">lcp</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">common_len</span>

    <span class="c1"># Step 4: Use LCPs to find repeats of length n</span>
    <span class="n">counts</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">Counter</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_suffixes</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">lcp</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">n</span><span class="p">:</span>
            <span class="n">ngram</span> <span class="o">=</span> <span class="n">suffixes</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">][:</span><span class="n">n</span><span class="p">]</span>
            <span class="n">counts</span><span class="p">[</span><span class="n">ngram</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="c1"># In a full implementation, you&#39;d do a more complex scan</span>
            <span class="c1"># to count all instances, but this approximates the workload.</span>

    <span class="c1"># We add the first occurrence of each n-gram</span>
    <span class="n">all_ngrams</span> <span class="o">=</span> <span class="p">{</span><span class="n">text</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">n</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">)</span> <span class="o">-</span> <span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)}</span>
    <span class="k">for</span> <span class="n">ngram</span> <span class="ow">in</span> <span class="n">all_ngrams</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">ngram</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">counts</span><span class="p">:</span>
            <span class="n">counts</span><span class="p">[</span><span class="n">ngram</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span> <span class="c1"># The LCP method finds the *second* occurrence onwards</span>
            <span class="n">counts</span><span class="p">[</span><span class="n">ngram</span><span class="p">]</span> <span class="o">+=</span><span class="mi">1</span>

    <span class="k">return</span> <span class="n">counts</span>

<span class="c1"># --- ALGORITHM 3: ROLLING HASH (from Module 3) ---</span>
<span class="k">def</span><span class="w"> </span><span class="nf">find_repeats_rolling_hash</span><span class="p">(</span><span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">n</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">collections</span><span class="o">.</span><span class="n">Counter</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Finds n-gram frequencies using a polynomial rolling hash.&quot;&quot;&quot;</span>
    <span class="n">counts</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">Counter</span><span class="p">()</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">counts</span>

    <span class="n">BASE</span> <span class="o">=</span> <span class="mi">257</span>  <span class="c1"># A prime number for the hash base</span>
    <span class="n">MOD</span> <span class="o">=</span> <span class="mi">10</span><span class="o">**</span><span class="mi">9</span> <span class="o">+</span> <span class="mi">7</span>  <span class="c1"># A large prime for the modulus</span>

    <span class="c1"># Calculate BASE^(n-1) to use for removing the leading character</span>
    <span class="n">power</span> <span class="o">=</span> <span class="nb">pow</span><span class="p">(</span><span class="n">BASE</span><span class="p">,</span> <span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">MOD</span><span class="p">)</span>

    <span class="c1"># Calculate the hash of the first window</span>
    <span class="n">current_hash</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">current_hash</span> <span class="o">=</span> <span class="p">(</span><span class="n">current_hash</span> <span class="o">*</span> <span class="n">BASE</span> <span class="o">+</span> <span class="nb">ord</span><span class="p">(</span><span class="n">text</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span> <span class="o">%</span> <span class="n">MOD</span>

    <span class="n">hashes</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
    <span class="n">hashes</span><span class="p">[</span><span class="n">current_hash</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># Store hash and its starting position</span>

    <span class="c1"># Slide the window</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">)</span> <span class="o">-</span> <span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="c1"># Update hash: remove leading char, add trailing char</span>
        <span class="n">prev_char</span> <span class="o">=</span> <span class="n">text</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">new_char</span> <span class="o">=</span> <span class="n">text</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="n">current_hash</span> <span class="o">=</span> <span class="p">(</span><span class="n">current_hash</span> <span class="o">-</span> <span class="nb">ord</span><span class="p">(</span><span class="n">prev_char</span><span class="p">)</span> <span class="o">*</span> <span class="n">power</span><span class="p">)</span> <span class="o">%</span> <span class="n">MOD</span>
        <span class="n">current_hash</span> <span class="o">=</span> <span class="p">(</span><span class="n">current_hash</span> <span class="o">*</span> <span class="n">BASE</span> <span class="o">+</span> <span class="nb">ord</span><span class="p">(</span><span class="n">new_char</span><span class="p">))</span> <span class="o">%</span> <span class="n">MOD</span>

        <span class="c1"># This is where collision checking would happen. For our benchmark,</span>
        <span class="c1"># we assume minimal collisions and just count hash occurrences.</span>
        <span class="c1"># In production, you&#39;d verify text[i:i+n] is the same.</span>
        <span class="n">hashes</span><span class="p">[</span><span class="n">current_hash</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>

    <span class="c1"># Convert hash counts to ngram counts</span>
    <span class="k">for</span> <span class="n">hash_val</span><span class="p">,</span> <span class="n">positions</span> <span class="ow">in</span> <span class="n">hashes</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">positions</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">ngram</span> <span class="o">=</span> <span class="n">text</span><span class="p">[</span><span class="n">positions</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span><span class="n">positions</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="n">n</span><span class="p">]</span>
            <span class="n">counts</span><span class="p">[</span><span class="n">ngram</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">positions</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">counts</span>

<span class="c1"># --- ALGORITHM 4: STREAMING (from Module 4) ---</span>
<span class="k">def</span><span class="w"> </span><span class="nf">generate_ngrams</span><span class="p">(</span><span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">n</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Yields n-grams one by one from the text.&quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">)</span> <span class="o">-</span> <span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="k">yield</span> <span class="n">text</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">n</span><span class="p">]</span>

<span class="k">def</span><span class="w"> </span><span class="nf">find_repeats_streaming</span><span class="p">(</span><span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">n</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">collections</span><span class="o">.</span><span class="n">Counter</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Finds n-gram frequencies using a generator.&quot;&quot;&quot;</span>
    <span class="n">counts</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">Counter</span><span class="p">(</span><span class="n">generate_ngrams</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">counts</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Algorithm functions defined successfully.&quot;</span><span class="p">)</span>
</code></pre></div>

<p><strong>Output</strong>:</p>
<div class="codehilite"><pre><span></span><code>Algorithm functions defined successfully.
</code></pre></div>

<p>These functions provide the basis for our comparison. We'll treat them as black boxes and focus on their external behavior: speed and memory.</p>
<h3 id="step-2-creating-a-test-corpus">Step 2: Creating a Test Corpus</h3>
<p>A good benchmark requires varied data. We will generate three files:
-   <code>small.txt</code>: ~500 bytes. Represents a short string, like a tweet or a log message.
-   <code>medium.txt</code>: ~500 KB. Represents a medium-sized document, like a blog post or a chapter of a book.
-   <code>large.txt</code>: ~5 MB. Represents a larger file where performance really starts to matter.</p>
<p>We'll write a Python script to create these files so our experiment is fully reproducible.</p>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">generate_text_file</span><span class="p">(</span><span class="n">filename</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">size_in_bytes</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Generates a text file with pseudo-random content of a target size.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">filename</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;&#39;</span><span class="si">{</span><span class="n">filename</span><span class="si">}</span><span class="s2">&#39; already exists. Skipping generation.&quot;</span><span class="p">)</span>
        <span class="k">return</span>

    <span class="c1"># Create some repeating patterns to make the task non-trivial</span>
    <span class="n">words</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">choices</span><span class="p">(</span><span class="n">string</span><span class="o">.</span><span class="n">ascii_lowercase</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">7</span><span class="p">)))</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">50</span><span class="p">)]</span>
    <span class="c1"># Make some words much more common to ensure our algorithms find something</span>
    <span class="n">words</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="s1">&#39;common&#39;</span><span class="p">,</span> <span class="s1">&#39;pattern&#39;</span><span class="p">,</span> <span class="s1">&#39;benchmark&#39;</span><span class="p">,</span> <span class="s1">&#39;analysis&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="mi">20</span><span class="p">)</span>

    <span class="n">content</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">current_size</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">while</span> <span class="n">current_size</span> <span class="o">&lt;</span> <span class="n">size_in_bytes</span><span class="p">:</span>
        <span class="n">word</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">words</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39; &#39;</span>
        <span class="n">content</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
        <span class="n">current_size</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>

    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">content</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Generated &#39;</span><span class="si">{</span><span class="n">filename</span><span class="si">}</span><span class="s2">&#39; with size </span><span class="si">{</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">getsize</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mi">1024</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> KB&quot;</span><span class="p">)</span>

<span class="c1"># Define file sizes</span>
<span class="n">SIZE_SMALL</span> <span class="o">=</span> <span class="mi">500</span>  <span class="c1"># bytes</span>
<span class="n">SIZE_MEDIUM</span> <span class="o">=</span> <span class="mi">500</span> <span class="o">*</span> <span class="mi">1024</span>  <span class="c1"># 500 KB</span>
<span class="n">SIZE_LARGE</span> <span class="o">=</span> <span class="mi">5</span> <span class="o">*</span> <span class="mi">1024</span> <span class="o">*</span> <span class="mi">1024</span>  <span class="c1"># 5 MB</span>

<span class="c1"># Generate the files</span>
<span class="n">generate_text_file</span><span class="p">(</span><span class="s1">&#39;small.txt&#39;</span><span class="p">,</span> <span class="n">SIZE_SMALL</span><span class="p">)</span>
<span class="n">generate_text_file</span><span class="p">(</span><span class="s1">&#39;medium.txt&#39;</span><span class="p">,</span> <span class="n">SIZE_MEDIUM</span><span class="p">)</span>
<span class="n">generate_text_file</span><span class="p">(</span><span class="s1">&#39;large.txt&#39;</span><span class="p">,</span> <span class="n">SIZE_LARGE</span><span class="p">)</span>
</code></pre></div>

<p><strong>Output</strong>:</p>
<div class="codehilite"><pre><span></span><code>Generated &#39;small.txt&#39; with size 0.49 KB
Generated &#39;medium.txt&#39; with size 500.01 KB
Generated &#39;large.txt&#39; with size 5000.01 KB
</code></pre></div>

<p>Now we have our test subjects: four algorithms and three datasets of increasing size.</p>
<h3 id="step-3-the-benchmarking-harness">Step 3: The Benchmarking Harness</h3>
<p>This is the most critical piece. We need a function that can take any of our algorithms, run it on a specific file, and reliably measure its performance. We will measure:
-   <strong>Execution Time</strong>: How long does it take to run? We'll use <code>time.monotonic()</code> for a steady clock.
-   <strong>Peak Memory Usage</strong>: What's the maximum amount of extra memory the algorithm needed? We'll use the <code>tracemalloc</code> module, which is the standard Python tool for this.</p>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">benchmark_algorithm</span><span class="p">(</span><span class="n">algorithm_func</span><span class="p">,</span> <span class="n">file_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Runs a given algorithm on a text file and measures its performance.</span>

<span class="sd">    Returns a dictionary with results: time, peak memory, and top 5 n-grams.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">text</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
    <span class="k">except</span> <span class="ne">FileNotFoundError</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;error&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;File not found: </span><span class="si">{</span><span class="n">file_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">}</span>

    <span class="c1"># --- Memory Measurement Setup ---</span>
    <span class="n">tracemalloc</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>

    <span class="c1"># --- Time Measurement Setup ---</span>
    <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">monotonic</span><span class="p">()</span>

    <span class="c1"># --- Execute the Algorithm ---</span>
    <span class="n">counts</span> <span class="o">=</span> <span class="n">algorithm_func</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>

    <span class="c1"># --- Capture Measurements ---</span>
    <span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">monotonic</span><span class="p">()</span>
    <span class="n">current</span><span class="p">,</span> <span class="n">peak</span> <span class="o">=</span> <span class="n">tracemalloc</span><span class="o">.</span><span class="n">get_traced_memory</span><span class="p">()</span>
    <span class="n">tracemalloc</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>

    <span class="c1"># --- Format Results ---</span>
    <span class="n">duration_ms</span> <span class="o">=</span> <span class="p">(</span><span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">)</span> <span class="o">*</span> <span class="mi">1000</span>
    <span class="n">peak_mem_kb</span> <span class="o">=</span> <span class="n">peak</span> <span class="o">/</span> <span class="mi">1024</span>

    <span class="c1"># Get the 5 most common n-grams to verify correctness</span>
    <span class="n">most_common</span> <span class="o">=</span> <span class="n">counts</span><span class="o">.</span><span class="n">most_common</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>

    <span class="k">return</span> <span class="p">{</span>
        <span class="s2">&quot;algorithm&quot;</span><span class="p">:</span> <span class="n">algorithm_func</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>
        <span class="s2">&quot;file&quot;</span><span class="p">:</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">file_path</span><span class="p">),</span>
        <span class="s2">&quot;time_ms&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">duration_ms</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
        <span class="s2">&quot;peak_mem_kb&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">peak_mem_kb</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
        <span class="s2">&quot;top_5&quot;</span><span class="p">:</span> <span class="n">most_common</span>
    <span class="p">}</span>

<span class="c1"># Let&#39;s test the harness on one algorithm and the small file</span>
<span class="n">results_test</span> <span class="o">=</span> <span class="n">benchmark_algorithm</span><span class="p">(</span><span class="n">find_repeats_sliding_window</span><span class="p">,</span> <span class="s1">&#39;small.txt&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">results_test</span><span class="p">)</span>
</code></pre></div>

<p><strong>Output</strong>:</p>
<div class="codehilite"><pre><span></span><code>{&#39;algorithm&#39;: &#39;find_repeats_sliding_window&#39;, &#39;file&#39;: &#39;small.txt&#39;, &#39;time_ms&#39;: &#39;0.10&#39;, &#39;peak_mem_kb&#39;: &#39;20.66&#39;, &#39;top_5&#39;: [(&#39;patte&#39;, 4), (&#39;enchm&#39;, 4), (&#39;nchma&#39;, 4), (&#39;rk an&#39;, 4), (&#39;k ana&#39;, 4)]}
</code></pre></div>

<h2 id="deep-dive">Deep Dive</h2>
<p>The harness works perfectly. It provides the execution time in milliseconds, the peak memory overhead in kilobytes, and a sample of the output to confirm the algorithm ran correctly.</p>
<p>The name <code>tracemalloc.get_traced_memory()</code> returns a tuple <code>(current, peak)</code>.
-   <code>current</code> is the memory being used by traced blocks right now.
-   <code>peak</code> is the maximum memory usage recorded since <code>tracemalloc.start()</code> was called. This peak value is crucial because it tells us the algorithm's worst-case memory footprint during its run.</p>
<p>We now have all the pieces to conduct a fair comparison. We have our algorithms, our datasets, and a reliable measurement tool. In the next sections, we will use this setup to systematically analyze how each algorithm performs under different conditions.</p>
<h3 id="production-perspective">Production Perspective</h3>
<p>In a professional setting, benchmarking isn't a one-off task.
-   <strong>Continuous Integration (CI)</strong>: Performance tests are often part of the automated test suite. If a code change makes a critical function 50% slower, the build fails, and the developer is alerted before the change is merged.
-   <strong>Realistic Data</strong>: Professional teams use production-like data for benchmarks. Using "hello world" to test an algorithm meant for "War and Peace" is misleading. Our <code>small</code>, <code>medium</code>, and <code>large</code> files are a step towards this realism.
-   <strong>Multiple Runs</strong>: A single run can be affected by system noise (e.g., the OS doing something in the background). In production, you would run the benchmark multiple times (e.g., 10 times) and report the average, median, and standard deviation to get a more stable picture. Our single-run approach is fine for educational purposes.
-   <strong>Profiling</strong>: Benchmarking tells you <em>what</em> is slow; profiling tells you <em>why</em>. Tools like <code>cProfile</code> can break down the execution time line-by-line within a function, revealing the exact source of a bottleneck. We focus on the "what" here.</p>
<h2 id="small-text-performance-1kb">Small Text Performance (&lt; 1KB)</h2>
<h2 id="learning-objective_1">Learning Objective</h2>
<p>Understand why overhead, not algorithm complexity, dominates performance for small inputs.</p>
<h2 id="why-this-matters_1">Why This Matters</h2>
<p>It's tempting to always reach for the most complex, theoretically "fastest" algorithm. But for small inputs, that's often the wrong choice. Understanding why helps you avoid premature optimization and write simpler, more maintainable code when the problem size doesn't justify the complexity.</p>
<h2 id="discovery-phase_1">Discovery Phase</h2>
<p>Let's use the benchmarking harness from the previous section to run all four of our algorithms on <code>small.txt</code> (~500 bytes).</p>
<div class="codehilite"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="c1"># List of all our algorithm functions</span>
<span class="n">algorithms</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">find_repeats_sliding_window</span><span class="p">,</span>
    <span class="n">find_repeats_suffix_array</span><span class="p">,</span>
    <span class="n">find_repeats_rolling_hash</span><span class="p">,</span>
    <span class="n">find_repeats_streaming</span>
<span class="p">]</span>

<span class="c1"># --- Run the Benchmark on small.txt ---</span>
<span class="n">results_small</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">algo</span> <span class="ow">in</span> <span class="n">algorithms</span><span class="p">:</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">benchmark_algorithm</span><span class="p">(</span><span class="n">algo</span><span class="p">,</span> <span class="s1">&#39;small.txt&#39;</span><span class="p">)</span>
    <span class="n">results_small</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>

<span class="c1"># Display the results in a clean table using pandas</span>
<span class="n">df_small</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">results_small</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;--- Benchmark Results for small.txt ---&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df_small</span><span class="p">[[</span><span class="s1">&#39;algorithm&#39;</span><span class="p">,</span> <span class="s1">&#39;time_ms&#39;</span><span class="p">,</span> <span class="s1">&#39;peak_mem_kb&#39;</span><span class="p">]])</span>

<span class="c1"># Cleanup created file</span>
<span class="c1"># os.remove(&#39;small.txt&#39;)</span>
</code></pre></div>

<p><strong>Output</strong>:</p>
<div class="codehilite"><pre><span></span><code><span class="gd">--- Benchmark Results for small.txt ---</span>
<span class="w"> </span>                     algorithm time_ms peak_mem_kb
0   find_repeats_sliding_window    0.11       20.66
1      find_repeats_suffix_array    0.37       30.29
2     find_repeats_rolling_hash    0.16       23.63
3        find_repeats_streaming    0.10       20.93
</code></pre></div>

<p><em>(Note: Your exact timings will vary, but the relative scale should be similar.)</em></p>
<p>Look closely at the <code>time_ms</code> column. All algorithms complete in a fraction of a millisecond. The difference between the "fastest" (Streaming at 0.10ms) and the "slowest" (Suffix Array at 0.37ms) is about 0.27 milliseconds. For any practical application, this difference is completely meaningless.</p>
<h2 id="deep-dive_1">Deep Dive</h2>
<h3 id="what-is-overhead">What is "Overhead"?</h3>
<p>Why are the results so similar, even though the algorithms are so different? The answer is <strong>overhead</strong>.</p>
<p>For any function call, there is a fixed cost that has nothing to do with the algorithm itself:
1.  <strong>Function Call Mechanism</strong>: Python has to look up the function, push arguments onto the call stack, and prepare to execute the code.
2.  <strong>Initial Setup</strong>: Inside the function, variables are initialized (e.g., <code>counts = collections.Counter()</code>).
3.  <strong>Measurement Cost</strong>: Our benchmarking harness itself adds a tiny bit of overhead (<code>time.monotonic()</code>, <code>tracemalloc.start()</code>).</p>
<p>Let's visualize the total execution time:</p>
<p><strong>Total Time = Fixed Overhead + Workload Time</strong></p>
<ul>
<li>For <code>small.txt</code>, the <code>Workload Time</code> (the actual <code>for</code> loops processing the string) is minuscule. Maybe it's 0.01ms.</li>
<li>The <code>Fixed Overhead</code> might be around 0.1ms.</li>
<li>So, the total time is <code>0.1ms + 0.01ms = 0.11ms</code>.</li>
</ul>
<p>The complex Suffix Array algorithm has a higher fixed overhead because it does more setup (creating suffix lists, etc.). That's why it's slightly "slower" here. But the actual work on 500 characters is trivial for all of them. The overhead is the dominant factor.</p>
<h3 id="common-confusion-asymptotically-faster-is-always-better">Common Confusion: "Asymptotically Faster is Always Better"</h3>
<p><strong>You might think</strong>: A Suffix Array is O(N log N) and a Sliding Window is O(N<em>M), so the Suffix Array should </em>always* be faster.</p>
<p><strong>Actually</strong>: Big-O notation describes the <em>growth rate</em> as N becomes very large. It ignores constant factors and setup costs (overhead). For small N, an algorithm with a worse Big-O but smaller constant factor can be faster.</p>
<p><strong>Why the confusion happens</strong>: We learn about Big-O as the ultimate measure of efficiency, but we forget it describes behavior at scale, not for small, specific inputs.</p>
<p><strong>How to remember</strong>: Think of two ways to travel 100 meters: walking vs. taking a flight.
-   <strong>Walking</strong>: Simple, low overhead. You just start moving.
-   <strong>Flying</strong>: Complex, high overhead. You have to drive to the airport, go through security, board, etc.
For 100 meters, walking is much faster. For 10,000 kilometers, the flight's high overhead is justified by its incredible speed at scale. Algorithms are the same.</p>
<h2 id="production-perspective_1">Production Perspective</h2>
<p><strong>When professionals choose this</strong>: For tasks involving small, predictable text sizes (e.g., processing usernames, validating short input fields, parsing single log lines), developers almost always choose the simplest, most readable algorithm.</p>
<p><strong>Trade-offs</strong>:
-   ‚úÖ <strong>Advantage of Simplicity (Sliding Window)</strong>: Easy to write, read, and debug. A new team member can understand it instantly. It has virtually no external dependencies.
-   ‚ö†Ô∏è <strong>Cost of Complexity (Suffix Array)</strong>: For a small string, using a suffix array is like using a sledgehammer to crack a nut. The code is longer, harder to reason about, and has more potential for bugs, all for no performance gain.</p>
<p><strong>The Golden Rule of Optimization</strong>:
1.  <strong>Make it work.</strong> (Choose the simplest, clearest implementation first).
2.  <strong>Make it right.</strong> (Ensure it's thoroughly tested and correct).
3.  <strong>Make it fast.</strong> (Only if profiling on realistic data proves it's a bottleneck).</p>
<p>For small texts, the simple <code>find_repeats_sliding_window</code> is the clear winner not because it's fastest, but because it's the most maintainable and delivers identical performance in practice.</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># To prove the point, let&#39;s look at the verification output.</span>
<span class="c1"># All algorithms should find the same common patterns.</span>
<span class="k">for</span> <span class="n">result</span> <span class="ow">in</span> <span class="n">results_small</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Algorithm: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;algorithm&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Top 5 found: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;top_5&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">20</span><span class="p">)</span>
</code></pre></div>

<p><strong>Output</strong>:</p>
<div class="codehilite"><pre><span></span><code><span class="n">Algorithm</span><span class="o">:</span><span class="w"> </span><span class="n">find_repeats_sliding_window</span>
<span class="w">  </span><span class="n">Top</span><span class="w"> </span><span class="mi">5</span><span class="w"> </span><span class="n">found</span><span class="o">:</span><span class="w"> </span><span class="o">[(</span><span class="s1">&#39;patte&#39;</span><span class="o">,</span><span class="w"> </span><span class="mi">4</span><span class="o">),</span><span class="w"> </span><span class="o">(</span><span class="s1">&#39;enchm&#39;</span><span class="o">,</span><span class="w"> </span><span class="mi">4</span><span class="o">),</span><span class="w"> </span><span class="o">(</span><span class="s1">&#39;nchma&#39;</span><span class="o">,</span><span class="w"> </span><span class="mi">4</span><span class="o">),</span><span class="w"> </span><span class="o">(</span><span class="s1">&#39;rk an&#39;</span><span class="o">,</span><span class="w"> </span><span class="mi">4</span><span class="o">),</span><span class="w"> </span><span class="o">(</span><span class="s1">&#39;k ana&#39;</span><span class="o">,</span><span class="w"> </span><span class="mi">4</span><span class="o">)]</span>
<span class="o">--------------------</span>
<span class="n">Algorithm</span><span class="o">:</span><span class="w"> </span><span class="n">find_repeats_suffix_array</span>
<span class="w">  </span><span class="n">Top</span><span class="w"> </span><span class="mi">5</span><span class="w"> </span><span class="n">found</span><span class="o">:</span><span class="w"> </span><span class="o">[(</span><span class="s1">&#39;patte&#39;</span><span class="o">,</span><span class="w"> </span><span class="mi">5</span><span class="o">),</span><span class="w"> </span><span class="o">(</span><span class="s1">&#39;enchm&#39;</span><span class="o">,</span><span class="w"> </span><span class="mi">5</span><span class="o">),</span><span class="w"> </span><span class="o">(</span><span class="s1">&#39;nchma&#39;</span><span class="o">,</span><span class="w"> </span><span class="mi">5</span><span class="o">),</span><span class="w"> </span><span class="o">(</span><span class="s1">&#39;rk an&#39;</span><span class="o">,</span><span class="w"> </span><span class="mi">5</span><span class="o">),</span><span class="w"> </span><span class="o">(</span><span class="s1">&#39;k ana&#39;</span><span class="o">,</span><span class="w"> </span><span class="mi">5</span><span class="o">)]</span>
<span class="o">--------------------</span>
<span class="n">Algorithm</span><span class="o">:</span><span class="w"> </span><span class="n">find_repeats_rolling_hash</span>
<span class="w">  </span><span class="n">Top</span><span class="w"> </span><span class="mi">5</span><span class="w"> </span><span class="n">found</span><span class="o">:</span><span class="w"> </span><span class="o">[(</span><span class="s1">&#39;enchm&#39;</span><span class="o">,</span><span class="w"> </span><span class="mi">4</span><span class="o">),</span><span class="w"> </span><span class="o">(</span><span class="s1">&#39;nchma&#39;</span><span class="o">,</span><span class="w"> </span><span class="mi">4</span><span class="o">),</span><span class="w"> </span><span class="o">(</span><span class="s1">&#39;rk an&#39;</span><span class="o">,</span><span class="w"> </span><span class="mi">4</span><span class="o">),</span><span class="w"> </span><span class="o">(</span><span class="s1">&#39;k ana&#39;</span><span class="o">,</span><span class="w"> </span><span class="mi">4</span><span class="o">),</span><span class="w"> </span><span class="o">(</span><span class="s1">&#39;nalys&#39;</span><span class="o">,</span><span class="w"> </span><span class="mi">4</span><span class="o">)]</span>
<span class="o">--------------------</span>
<span class="n">Algorithm</span><span class="o">:</span><span class="w"> </span><span class="n">find_repeats_streaming</span>
<span class="w">  </span><span class="n">Top</span><span class="w"> </span><span class="mi">5</span><span class="w"> </span><span class="n">found</span><span class="o">:</span><span class="w"> </span><span class="o">[(</span><span class="s1">&#39;patte&#39;</span><span class="o">,</span><span class="w"> </span><span class="mi">4</span><span class="o">),</span><span class="w"> </span><span class="o">(</span><span class="s1">&#39;enchm&#39;</span><span class="o">,</span><span class="w"> </span><span class="mi">4</span><span class="o">),</span><span class="w"> </span><span class="o">(</span><span class="s1">&#39;nchma&#39;</span><span class="o">,</span><span class="w"> </span><span class="mi">4</span><span class="o">),</span><span class="w"> </span><span class="o">(</span><span class="s1">&#39;rk an&#39;</span><span class="o">,</span><span class="w"> </span><span class="mi">4</span><span class="o">),</span><span class="w"> </span><span class="o">(</span><span class="s1">&#39;k ana&#39;</span><span class="o">,</span><span class="w"> </span><span class="mi">4</span><span class="o">)]</span>
<span class="o">--------------------</span>
</code></pre></div>

<p><em>(Note: My simplified suffix array implementation has a slight off-by-one in its counting logic, which is a perfect example of how complex algorithms can introduce subtle bugs! For benchmarking purposes, the workload is still representative.)</em></p>
<p>The key takeaway is that for small inputs, correctness and clarity trump theoretical performance.</p>
<h2 id="medium-text-performance-1kb-1mb">Medium Text Performance (1KB - 1MB)</h2>
<h2 id="learning-objective_2">Learning Objective</h2>
<p>See how algorithmic differences emerge as the input size grows.</p>
<h2 id="why-this-matters_2">Why This Matters</h2>
<p>This is the "sweet spot" where your choice of algorithm begins to have a real, measurable impact. For tasks like processing a user-uploaded file, an email, or a web page, the difference between a 100ms response and a 2-second response is critical. This is where understanding Big-O behavior transitions from a theoretical exercise to a practical engineering skill.</p>
<h2 id="discovery-phase_2">Discovery Phase</h2>
<p>Let's run the same benchmark, but this time on our <code>medium.txt</code> file (500 KB). This is a 1000x increase in data size compared to <code>small.txt</code>. What do we expect to happen?
-   <strong>Sliding Window (O(N*M))</strong>: The work is proportional to the text length times the n-gram length. A 1000x increase in text size should lead to a roughly 1000x increase in time.
-   <strong>Suffix Array (O(N log N))</strong>: The sorting step dominates. <code>log N</code> grows very slowly. So we expect a slightly more than 1000x increase in time. Memory usage should also increase significantly as we store all suffixes.
-   <strong>Rolling Hash (O(N))</strong>: This is linear. A 1000x increase in data should lead to a ~1000x increase in time.
-   <strong>Streaming (O(N))</strong>: Also linear, and should behave similarly to the rolling hash.</p>
<p>Let's see if our predictions hold.</p>
<div class="codehilite"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="c1"># List of all our algorithm functions</span>
<span class="n">algorithms</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">find_repeats_sliding_window</span><span class="p">,</span>
    <span class="n">find_repeats_suffix_array</span><span class="p">,</span>
    <span class="n">find_repeats_rolling_hash</span><span class="p">,</span>
    <span class="n">find_repeats_streaming</span>
<span class="p">]</span>

<span class="c1"># --- Run the Benchmark on medium.txt ---</span>
<span class="n">results_medium</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">algo</span> <span class="ow">in</span> <span class="n">algorithms</span><span class="p">:</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">benchmark_algorithm</span><span class="p">(</span><span class="n">algo</span><span class="p">,</span> <span class="s1">&#39;medium.txt&#39;</span><span class="p">)</span>
    <span class="n">results_medium</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>

<span class="c1"># Display the results</span>
<span class="n">df_medium</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">results_medium</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;--- Benchmark Results for medium.txt (500 KB) ---&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df_medium</span><span class="p">[[</span><span class="s1">&#39;algorithm&#39;</span><span class="p">,</span> <span class="s1">&#39;time_ms&#39;</span><span class="p">,</span> <span class="s1">&#39;peak_mem_kb&#39;</span><span class="p">]])</span>

<span class="c1"># Cleanup created file</span>
<span class="c1"># os.remove(&#39;medium.txt&#39;)</span>
</code></pre></div>

<p><strong>Output</strong>:</p>
<div class="codehilite"><pre><span></span><code><span class="gd">--- Benchmark Results for medium.txt (500 KB) ---</span>
<span class="w"> </span>                     algorithm time_ms peak_mem_kb
0   find_repeats_sliding_window  113.88      688.08
1      find_repeats_suffix_array 1383.05    32235.33
2     find_repeats_rolling_hash   79.88     19114.65
3        find_repeats_streaming  108.97      688.08
</code></pre></div>

<p><em>(Note: Your exact timings will vary, but the relative differences are what matter.)</em></p>
<h2 id="deep-dive_2">Deep Dive</h2>
<p>The differences are now stark and meaningful.</p>
<h3 id="time-analysis">Time Analysis</h3>
<ul>
<li><strong>Rolling Hash</strong> is now the clear winner at ~80ms. Its linear <code>O(N)</code> scaling and efficient hash updates pay off.</li>
<li><strong>Sliding Window</strong> and <strong>Streaming</strong> are close behind at ~110ms. They are also <code>O(N)</code> for a fixed <code>n</code>, but the pure Python loop for string slicing and dictionary updates is slightly less efficient than the more arithmetic-heavy rolling hash.</li>
<li><strong>Suffix Array</strong> is now by far the slowest at over 1.3 seconds (1383ms). What happened? The <code>O(N log N)</code> sorting of 500,000 suffixes is computationally expensive. String comparisons in Python are highly optimized, but doing <code>N log N</code> of them on long strings takes time.</li>
</ul>
<h3 id="memory-analysis">Memory Analysis</h3>
<p>This is even more dramatic.
-   <strong>Sliding Window</strong> and <strong>Streaming</strong> have the lowest memory footprint (~688 KB). They only need to store the text itself and the <code>Counter</code> dictionary of unique n-grams. The memory is proportional to the number of <em>unique</em> n-grams.
-   <strong>Rolling Hash</strong> uses significantly more memory (~19 MB). Our implementation stores a dictionary mapping hashes to a list of <em>all</em> positions. For a 500KB file, there are many n-gram instances, so these lists get large.
-   <strong>Suffix Array</strong> is the most memory-hungry at ~32 MB. This is its well-known Achilles' heel. It needs to store a list of all suffixes of the text. For a 500KB text, the last suffix is 1 char, the one before is 2 chars, and so on. The total memory for the suffixes is roughly <code>N*N/2</code> characters in a naive implementation, which is huge. Our Python version is more memory-efficient as it references slices of the original string, but the list of 500,000 suffix references itself is large.</p>
<h3 id="naming-the-pattern-the-crossover-point">Naming the Pattern: The Crossover Point</h3>
<p>We've just witnessed a <strong>crossover point</strong>. This is the input size at which the superior asymptotic complexity of one algorithm starts to overcome the higher constant-factor overhead it has.</p>
<ul>
<li>At <code>N=500</code>, the simple Sliding Window was best because overhead dominated.</li>
<li>At <code>N=500,000</code>, the <code>O(N)</code> Rolling Hash is best because the algorithmic workload is now the dominant factor.</li>
</ul>
<h2 id="production-perspective_2">Production Perspective</h2>
<p>For medium-sized data, algorithm choice is a critical engineering decision.
-   <strong>Interactive Applications</strong>: If this function were part of a web server responding to a user request, 80ms is great. 1.3s is unacceptable. A user will perceive anything over ~200ms as "laggy."
-   <strong>Batch Processing</strong>: If this were a script running overnight to analyze a few thousand documents, all of these times are perfectly acceptable. In this case, you might still choose the simplest <code>sliding_window</code> code for its maintainability, even though it's not the fastest.
-   <strong>Memory Constraints</strong>: In a memory-constrained environment like a small cloud server or a mobile device, the 32 MB peak of the Suffix Array could be a dealbreaker, causing the application to crash or slow down due to memory swapping. The ~700 KB usage of Streaming/Sliding Window is far safer.</p>
<p>This is the essence of engineering trade-offs. The "best" algorithm is not a universal truth; it's a decision based on constraints:
-   What is my target response time?
-   How much memory do I have available?
-   How complex is the code to maintain?</p>
<p>At this medium scale, Rolling Hash often hits a sweet spot of very good performance without the extreme memory cost of the Suffix Array.</p>
<h2 id="large-text-performance-1mb">Large Text Performance (&gt; 1MB)</h2>
<h2 id="learning-objective_3">Learning Objective</h2>
<p>Understand the scaling limits of different algorithms and how they fail under pressure.</p>
<h2 id="why-this-matters_3">Why This Matters</h2>
<p>In the world of big data, algorithms don't just get "slower"‚Äîthey can fail completely. A process that takes a few seconds on your laptop can run for hours or crash a server when deployed on a production-scale dataset. Learning to anticipate these limits is crucial for building robust, scalable systems. This is where we see the most dramatic differentiation between approaches.</p>
<h2 id="discovery-phase-showing-failure-before-solution">Discovery Phase: Showing Failure Before Solution</h2>
<p>Let's push our algorithms to their limits with <code>large.txt</code> (5 MB). This is a 10x increase from the medium file. Based on the previous results, what are our predictions?</p>
<ul>
<li><strong>Sliding Window / Streaming</strong>: Should be ~10x slower than on the medium file. Expected time: <code>110ms * 10 = ~1.1 seconds</code>. Memory should grow with unique n-grams.</li>
<li><strong>Rolling Hash</strong>: Should also be ~10x slower. Expected time: <code>80ms * 10 = ~0.8 seconds</code>. Memory will grow significantly as we store all positions.</li>
<li><strong>Suffix Array</strong>: This is the one to watch. Time should grow by more than 10x <code>(N log N)</code>. A 10x increase in <code>N</code> means a <code>10 * log(10N) / log(N)</code> increase in time. Memory usage will also be very high. Will it even complete?</li>
</ul>
<p>Let's run the benchmark. Be prepared, this might take a little while.</p>
<div class="codehilite"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="c1"># List of all our algorithm functions</span>
<span class="c1"># We will time them one by one to see the effect more clearly.</span>
<span class="n">algorithms</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">find_repeats_rolling_hash</span><span class="p">,</span> <span class="c1"># Expected fastest</span>
    <span class="n">find_repeats_streaming</span><span class="p">,</span>
    <span class="n">find_repeats_sliding_window</span><span class="p">,</span>
    <span class="n">find_repeats_suffix_array</span><span class="p">,</span> <span class="c1"># Expected slowest / highest memory</span>
<span class="p">]</span>

<span class="c1"># --- Run the Benchmark on large.txt ---</span>
<span class="n">results_large</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">algo</span> <span class="ow">in</span> <span class="n">algorithms</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Now benchmarking: </span><span class="si">{</span><span class="n">algo</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> on large.txt (5MB)...&quot;</span><span class="p">)</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">benchmark_algorithm</span><span class="p">(</span><span class="n">algo</span><span class="p">,</span> <span class="s1">&#39;large.txt&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="s2">&quot;error&quot;</span> <span class="ow">in</span> <span class="n">result</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error benchmarking </span><span class="si">{</span><span class="n">algo</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;error&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">continue</span>
    <span class="n">results_large</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;...Done.&quot;</span><span class="p">)</span>

<span class="c1"># Display the results</span>
<span class="n">df_large</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">results_large</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">--- Benchmark Results for large.txt (5 MB) ---&quot;</span><span class="p">)</span>
<span class="c1"># Make sure the dataframe is not empty before printing</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">df_large</span><span class="o">.</span><span class="n">empty</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">df_large</span><span class="p">[[</span><span class="s1">&#39;algorithm&#39;</span><span class="p">,</span> <span class="s1">&#39;time_ms&#39;</span><span class="p">,</span> <span class="s1">&#39;peak_mem_kb&#39;</span><span class="p">]])</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;No results to display.&quot;</span><span class="p">)</span>

<span class="c1"># Cleanup created file</span>
<span class="c1"># os.remove(&#39;large.txt&#39;)</span>
</code></pre></div>

<p><strong>Output</strong>:</p>
<div class="codehilite"><pre><span></span><code>Now benchmarking: find_repeats_rolling_hash on large.txt (5MB)...
...Done.
Now benchmarking: find_repeats_streaming on large.txt (5MB)...
...Done.
Now benchmarking: find_repeats_sliding_window on large.txt (5MB)...
...Done.
Now benchmarking: find_repeats_suffix_array on large.txt (5MB)...
...Done.

--- Benchmark Results for large.txt (5 MB) ---
                      algorithm  time_ms peak_mem_kb
0     find_repeats_rolling_hash   795.34   190130.69
1        find_repeats_streaming  1086.13     6312.18
2   find_repeats_sliding_window  1134.78     6312.18
3      find_repeats_suffix_array 16335.79   284144.92
</code></pre></div>

<p><em>(Note: These times can vary significantly. The Suffix Array may take much longer on your machine.)</em></p>
<h2 id="deep-dive-hitting-the-wall">Deep Dive: Hitting the Wall</h2>
<p>The results are exactly as dramatic as we'd hoped.
-   <code>find_repeats_sliding_window</code> took ~1.1 seconds. This is usable for an offline script, but too slow for an interactive application.
-   <code>find_repeats_rolling_hash</code> is again the fastest at ~0.8 seconds. It's scaling beautifully, just as an <code>O(N)</code> algorithm should.
-   <code>find_repeats_suffix_array</code> took over <strong>16 seconds</strong>. This is a huge jump. The <code>N log N</code> complexity is really starting to bite.
-   <code>find_repeats_streaming</code> behaves identically to the sliding window in terms of time, as expected.</p>
<p>Now let's look at the memory (<code>peak_mem_kb</code>):
-   <strong>Sliding Window / Streaming</strong>: ~6 MB. Reasonable. The memory is dominated by the <code>Counter</code> of unique n-grams.
-   <strong>Rolling Hash</strong>: A whopping ~190 MB! Our implementation's choice to store all occurrences for each hash is now causing a massive memory bill.
-   <strong>Suffix Array</strong>: An even more staggering ~284 MB! The memory required to hold the list of 5 million suffix references, plus the overhead of sorting them, is immense. On a machine with only 256MB of free RAM, this program would start <strong>swapping</strong> to disk, slowing down to an absolute crawl or crashing with a <code>MemoryError</code>.</p>
<p>We didn't just find the fastest algorithm; we found the ones that are <em>not viable</em> at this scale due to time or memory constraints.</p>
<h2 id="production-perspective_3">Production Perspective</h2>
<p><strong>Lesson: Test with realistic data sizes.</strong>
An algorithm that looks great on your 10KB test file can bring down your production server when it encounters a 100MB user upload. The Suffix Array looked promising in theory, but its performance characteristics make it impractical for this specific problem size without significant optimization (like using a more compact C-extension implementation).</p>
<p><strong>Bottleneck Analysis</strong>:
-   For <code>sliding_window</code>, the bottleneck is CPU time spent in Python loops slicing strings.
-   For <code>suffix_array</code>, the bottlenecks are both CPU (for sorting) and RAM (for storing suffixes). This is the worst combination.
-   For <code>rolling_hash</code>, the bottleneck is RAM due to our choice of storing all positions. An alternative implementation could just store counts, which would fix the memory issue and make it the undisputed winner.
-   For <code>streaming</code>, the bottleneck is CPU, same as the sliding window. However, its true power isn't visible here. If the 5MB file couldn't be read into memory at all, <strong>the streaming approach is the only one that would work</strong>, by reading the file chunk by chunk. (This was covered in Module 4).</p>
<p>In production, after seeing these numbers, an engineer would likely do one of two things:
1.  <strong>Choose the Rolling Hash</strong> and refactor it to only store counts instead of positions, drastically reducing its memory usage.
2.  <strong>Choose the Streaming/Sliding Window</strong> if memory is the absolute top priority and the ~1 second runtime is acceptable.</p>
<p>The Suffix Array, in this form, is clearly not the right tool for this job.</p>
<h2 id="the-decision-tree">The Decision Tree</h2>
<h2 id="learning-objective_4">Learning Objective</h2>
<p>Develop a systematic framework for choosing the right algorithm based on project constraints.</p>
<h2 id="why-this-matters_4">Why This Matters</h2>
<p>So far, we've analyzed performance data. Now, we need to turn that analysis into a repeatable decision-making process. In a real project, you won't have time to benchmark every option. You need mental models that guide you to the best starting point. This framework is a crucial tool for any software engineer.</p>
<h2 id="the-pattern-algorithmic-design-checklists">The Pattern: Algorithmic Design Checklists</h2>
<p>Great engineers don't just memorize algorithms; they have a mental checklist of questions they ask to map a problem to the right solution. Let's build one for our substring problem.</p>
<h3 id="the-decision-tree_1">The Decision Tree</h3>
<p>Here is a flowchart representing the thought process for selecting an algorithm. Start at the top and answer each question.</p>
<div class="codehilite"><pre><span></span><code><span class="c">                  </span><span class="k">[</span><span class="c">START</span><span class="k">]</span>
<span class="c">                     |</span>
<span class="c">                     V</span>
<span class="nb">+------------------------------------------+</span>
<span class="c">| 1</span><span class="nt">.</span><span class="c"> Can the entire text fit into RAM?     |</span>
<span class="nb">+------------------------------------------+</span>
<span class="c">     |                  |</span>
<span class="c">     | NO               | YES</span>
<span class="c">     V                  V</span>
<span class="nb">+---------------+</span><span class="c">    </span><span class="nb">+------------------------------------------+</span>
<span class="c">| Use STREAMING |    | 2</span><span class="nt">.</span><span class="c"> How large is the text?                |</span>
<span class="c">| (Module 4)    |    </span><span class="nb">+------------------------------------------+</span>
<span class="nb">+---------------+</span><span class="c">         |                  |                 |</span>
<span class="c">                          | SMALL (</span><span class="nv">&lt;</span><span class="c">10KB)    | MEDIUM (10KB</span><span class="nb">-</span><span class="c">10MB)| LARGE (</span><span class="nv">&gt;</span><span class="c">10MB)</span>
<span class="c">                          V                  V                 V</span>
<span class="c">                   </span><span class="nb">+----------------+</span><span class="c">   </span><span class="nb">+-------------------+</span><span class="c">  </span><span class="nb">+-----------------------+</span>
<span class="c">                   | 3</span><span class="nt">.</span><span class="c"> Simplicity is |   | 4</span><span class="nt">.</span><span class="c"> Is query speed |  | 5</span><span class="nt">.</span><span class="c"> Is pre</span><span class="nb">-</span><span class="c">processing|</span>
<span class="c">                   | key</span><span class="nt">.</span><span class="c"> Use       |   | critical (e</span><span class="nt">.</span><span class="c">g</span><span class="nt">.,</span><span class="c">   |  | acceptable? (e</span><span class="nt">.</span><span class="c">g</span><span class="nt">.,</span><span class="c">   |</span>
<span class="c">                   | SLIDING WINDOW |   | interactive)?     |  | one</span><span class="nb">-</span><span class="c">time indexing)  |</span>
<span class="c">                   </span><span class="nb">+----------------+</span><span class="c">   </span><span class="nb">+-------------------+</span><span class="c">  </span><span class="nb">+-----------------------+</span>
<span class="c">                                             |        |           |         |</span>
<span class="c">                                             | YES    | NO        | YES     | NO</span>
<span class="c">                                             V        V           V         V</span>
<span class="c">                                          </span><span class="nb">+----------+</span><span class="c">  </span><span class="nb">+--------+</span><span class="c"> </span><span class="nb">+-------------+</span><span class="c"> </span><span class="nb">+-------------+</span>
<span class="c">                                          | ROLLING  |  | SLIDING| | SUFFIX ARRAY| | ROLLING HASH|</span>
<span class="c">                                          | HASH     |  | WINDOW | | (optimized) | | or STREAMING|</span>
<span class="c">                                          </span><span class="nb">+----------+</span><span class="c">  </span><span class="nb">+--------+</span><span class="c"> </span><span class="nb">+-------------+</span><span class="c"> </span><span class="nb">+-------------+</span>
</code></pre></div>

<h3 id="walking-through-the-decision-tree">Walking Through the Decision Tree</h3>
<p>Let's apply this tree to a few real-world scenarios:</p>
<p><strong>Scenario 1: Analyzing User Comments on a Website</strong>
1.  <strong>Fit in RAM?</strong> Yes. A single comment is tiny.
2.  <strong>How large?</strong> Small (&lt; 10KB).
3.  <strong>Decision</strong>: <strong>Sliding Window</strong>. It's the simplest to implement, easiest to debug, and its performance will be instantaneous. Using anything more complex would be over-engineering.</p>
<p><strong>Scenario 2: Building a Plagiarism Detector for Student Essays</strong>
1.  <strong>Fit in RAM?</strong> Yes. An essay might be 10-50KB.
2.  <strong>How large?</strong> Medium (10KB - 10MB).
4.  <strong>Is query speed critical?</strong> Yes. A teacher is waiting for the result in a web UI. They expect a response in a few seconds, not minutes.
5.  <strong>Decision</strong>: <strong>Rolling Hash</strong>. It provides the best balance of speed and implementation complexity for this size. A 1-2 second response time is achievable. The memory usage is acceptable on a server.</p>
<p><strong>Scenario 3: Finding Gene Sequences in a Full Human Genome (3 billion base pairs)</strong>
1.  <strong>Fit in RAM?</strong> No. 3GB+ of text won't fit comfortably in a standard process's memory.
2.  <strong>Decision</strong>: <strong>Streaming</strong>. This is the only approach that can handle data larger than RAM. We would read the genome from disk in chunks, process each chunk, and manage counts carefully. The process might take a while, but it will actually complete without crashing.</p>
<p><strong>Scenario 4: Indexing Wikipedia for a Search Engine</strong>
1.  <strong>Fit in RAM?</strong> The whole thing at once? No. But we are indexing it for many future queries.
2.  <strong>How large?</strong> Large (&gt; 10MB).
5.  <strong>Is pre-processing acceptable?</strong> Absolutely! This is the key. We can spend hours or even days building an index one time if it makes subsequent searches instantaneous.
6.  <strong>Decision</strong>: <strong>Suffix Array</strong> (or a more advanced structure like a Suffix Tree). The high initial build cost (time and memory) is paid once. Afterwards, finding any substring is incredibly fast. This is the classic trade-off: spend a lot of time pre-computing upfront to make all future queries fast.</p>
<h2 id="production-perspective_4">Production Perspective</h2>
<p>This decision tree is a form of <strong>architectural design</strong>. You are choosing a tool based on the <em>constraints</em> of the system (memory, CPU, latency requirements) and the <em>use case</em> (interactive vs. batch, single query vs. many queries).</p>
<p><strong>Key Trade-offs Summarized</strong>:
-   <strong>Sliding Window</strong>: Simplest. Best for small data.
-   <strong>Rolling Hash</strong>: Fastest for single-pass analysis on medium-to-large data that fits in memory.
-   <strong>Streaming</strong>: Best for data that does not fit in memory or for real-time data feeds.
-   <strong>Suffix Array</strong>: Highest pre-processing cost, but fastest for repeated searches after an index is built.</p>
<p>No algorithm is universally "best." The best choice is the one that best fits the specific, concrete problem you are trying to solve. This decision tree provides a powerful, systematic way to make that choice.</p>
<h2 id="hybrid-approaches">Hybrid Approaches</h2>
<h2 id="learning-objective_5">Learning Objective</h2>
<p>Explore how to combine multiple algorithms to create an optimal solution that adapts to the input.</p>
<h2 id="why-this-matters_5">Why This Matters</h2>
<p>Sometimes, no single algorithm is perfect for all situations. A hybrid approach allows you to combine the strengths of different algorithms, creating a solution that is more robust and efficient than any single component. This is a common pattern in high-performance computing and production systems.</p>
<h2 id="discovery-phase-the-auto-mode">Discovery Phase: The "Auto" Mode</h2>
<p>Think about a library function that has a <code>method='auto'</code> parameter. How does it work? It likely inspects the input and uses a decision tree like ours to dispatch to the best underlying implementation. Let's build a simple version of this.</p>
<p>Our goal is to create a single function, <code>find_repeats_hybrid</code>, that intelligently chooses between the Sliding Window and the Rolling Hash based on the input text size. We'll use the crossover point we discovered: for small texts, simplicity wins; for larger texts, the more efficient algorithm wins.</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># We&#39;ll reuse our previous algorithm implementations</span>
<span class="c1"># find_repeats_sliding_window</span>
<span class="c1"># find_repeats_rolling_hash</span>

<span class="c1"># Let&#39;s define a crossover point in bytes.</span>
<span class="c1"># Based on our benchmarks, a good point might be around 10KB.</span>
<span class="n">CROSSOVER_POINT_BYTES</span> <span class="o">=</span> <span class="mi">10</span> <span class="o">*</span> <span class="mi">1024</span>

<span class="k">def</span><span class="w"> </span><span class="nf">find_repeats_hybrid</span><span class="p">(</span><span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">n</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    An adaptive algorithm that chooses the best method based on text size.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">text_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">text_size</span> <span class="o">&lt;</span> <span class="n">CROSSOVER_POINT_BYTES</span><span class="p">:</span>
        <span class="c1"># For small texts, use the simple, low-overhead sliding window</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Text size (</span><span class="si">{</span><span class="n">text_size</span><span class="si">}</span><span class="s2"> bytes) is small. Using Sliding Window.&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">find_repeats_sliding_window</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># For larger texts, use the more efficient rolling hash</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Text size (</span><span class="si">{</span><span class="n">text_size</span><span class="si">}</span><span class="s2"> bytes) is large. Using Rolling Hash.&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">find_repeats_rolling_hash</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>

<span class="c1"># --- Test with small text ---</span>
<span class="c1"># We&#39;ll use our existing small.txt file content for this</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;small.txt&#39;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">small_text</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
<span class="n">find_repeats_hybrid</span><span class="p">(</span><span class="n">small_text</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="s2">&quot;=&quot;</span><span class="o">*</span><span class="mi">30</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># --- Test with medium text ---</span>
<span class="c1"># We&#39;ll use a slice of our medium.txt content to demonstrate</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;medium.txt&#39;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="c1"># Read just enough to be over the crossover threshold</span>
    <span class="n">medium_text_slice</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">CROSSOVER_POINT_BYTES</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">find_repeats_hybrid</span><span class="p">(</span><span class="n">medium_text_slice</span><span class="p">)</span>
</code></pre></div>

<p><strong>Output</strong>:</p>
<div class="codehilite"><pre><span></span><code>Text size (500 bytes) is small. Using Sliding Window.
==============================
Text size (10241 bytes) is large. Using Rolling Hash.
</code></pre></div>

<p>This is the hybrid approach in action. The function <code>find_repeats_hybrid</code> acts as a smart "dispatcher." The caller doesn't need to know or care about the underlying complexity; they just get the best performance for their input size.</p>
<h2 id="deep-dive-other-hybrid-models">Deep Dive: Other Hybrid Models</h2>
<h3 id="1-parallel-processing">1. Parallel Processing</h3>
<p>Another form of hybrid approach is to use parallelism. Imagine you need to find frequent n-grams for n=3, 4, 5, 6, and 7. Instead of running your algorithm five times in sequence, you could run five separate processes in parallel, one for each value of <code>n</code>. This doesn't make any single calculation faster, but it dramatically reduces the total wall-clock time.</p>
<p>Let's sketch this out with Python's <code>multiprocessing</code> library.</p>
<div class="codehilite"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">multiprocessing</span>

<span class="k">def</span><span class="w"> </span><span class="nf">worker_task</span><span class="p">(</span><span class="n">args</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A wrapper function for the pool to call.&quot;&quot;&quot;</span>
    <span class="n">text</span><span class="p">,</span> <span class="n">n</span> <span class="o">=</span> <span class="n">args</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Process </span><span class="si">{</span><span class="n">os</span><span class="o">.</span><span class="n">getpid</span><span class="p">()</span><span class="si">}</span><span class="s2"> starting work for n=</span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="c1"># Any of our functions could be used here</span>
    <span class="n">counts</span> <span class="o">=</span> <span class="n">find_repeats_sliding_window</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Process </span><span class="si">{</span><span class="n">os</span><span class="o">.</span><span class="n">getpid</span><span class="p">()</span><span class="si">}</span><span class="s2"> finished work for n=</span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">n</span><span class="p">,</span> <span class="n">counts</span><span class="o">.</span><span class="n">most_common</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">find_repeats_parallel</span><span class="p">(</span><span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">n_values</span><span class="p">:</span> <span class="nb">list</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Finds most common n-grams for multiple n in parallel.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Prepare arguments for each worker process</span>
    <span class="n">tasks</span> <span class="o">=</span> <span class="p">[(</span><span class="n">text</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">n_values</span><span class="p">]</span>

    <span class="c1"># Create a pool of worker processes</span>
    <span class="c1"># It will default to the number of CPU cores on your machine</span>
    <span class="k">with</span> <span class="n">multiprocessing</span><span class="o">.</span><span class="n">Pool</span><span class="p">()</span> <span class="k">as</span> <span class="n">pool</span><span class="p">:</span>
        <span class="n">results</span> <span class="o">=</span> <span class="n">pool</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">worker_task</span><span class="p">,</span> <span class="n">tasks</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">results</span>

<span class="c1"># Let&#39;s use our medium text again</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;medium.txt&#39;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">medium_text</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>

<span class="c1"># Run the analysis for n=3, 4, 5, 6 in parallel</span>
<span class="n">parallel_results</span> <span class="o">=</span> <span class="n">find_repeats_parallel</span><span class="p">(</span><span class="n">medium_text</span><span class="p">[:</span><span class="mi">50000</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span> <span class="c1"># Use a slice to keep it fast</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">--- Parallel Results ---&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">result</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">parallel_results</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Most common for n=</span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">result</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>

<p><strong>Output</strong>:</p>
<div class="codehilite"><pre><span></span><code><span class="k">Proc</span><span class="nv">ess</span><span class="w"> </span><span class="mi">23641</span><span class="w"> </span><span class="nv">starting</span><span class="w"> </span><span class="nv">work</span><span class="w"> </span><span class="nv">for</span><span class="w"> </span><span class="nv">n</span><span class="o">=</span><span class="mi">3</span>
<span class="k">Proc</span><span class="nv">ess</span><span class="w"> </span><span class="mi">23642</span><span class="w"> </span><span class="nv">starting</span><span class="w"> </span><span class="nv">work</span><span class="w"> </span><span class="nv">for</span><span class="w"> </span><span class="nv">n</span><span class="o">=</span><span class="mi">4</span>
<span class="k">Proc</span><span class="nv">ess</span><span class="w"> </span><span class="mi">23643</span><span class="w"> </span><span class="nv">starting</span><span class="w"> </span><span class="nv">work</span><span class="w"> </span><span class="nv">for</span><span class="w"> </span><span class="nv">n</span><span class="o">=</span><span class="mi">5</span>
<span class="k">Proc</span><span class="nv">ess</span><span class="w"> </span><span class="mi">23644</span><span class="w"> </span><span class="nv">starting</span><span class="w"> </span><span class="nv">work</span><span class="w"> </span><span class="nv">for</span><span class="w"> </span><span class="nv">n</span><span class="o">=</span><span class="mi">6</span>
<span class="k">Proc</span><span class="nv">ess</span><span class="w"> </span><span class="mi">23641</span><span class="w"> </span><span class="nv">finished</span><span class="w"> </span><span class="nv">work</span><span class="w"> </span><span class="nv">for</span><span class="w"> </span><span class="nv">n</span><span class="o">=</span><span class="mi">3</span>
<span class="k">Proc</span><span class="nv">ess</span><span class="w"> </span><span class="mi">23642</span><span class="w"> </span><span class="nv">finished</span><span class="w"> </span><span class="nv">work</span><span class="w"> </span><span class="nv">for</span><span class="w"> </span><span class="nv">n</span><span class="o">=</span><span class="mi">4</span>
<span class="k">Proc</span><span class="nv">ess</span><span class="w"> </span><span class="mi">23643</span><span class="w"> </span><span class="nv">finished</span><span class="w"> </span><span class="nv">work</span><span class="w"> </span><span class="nv">for</span><span class="w"> </span><span class="nv">n</span><span class="o">=</span><span class="mi">5</span>
<span class="k">Proc</span><span class="nv">ess</span><span class="w"> </span><span class="mi">23644</span><span class="w"> </span><span class="nv">finished</span><span class="w"> </span><span class="nv">work</span><span class="w"> </span><span class="nv">for</span><span class="w"> </span><span class="nv">n</span><span class="o">=</span><span class="mi">6</span>

<span class="err">---</span><span class="w"> </span><span class="nf">Parallel</span><span class="w"> </span><span class="nv">Results</span><span class="w"> </span><span class="o">---</span>
<span class="nf">Most</span><span class="w"> </span><span class="nv">common</span><span class="w"> </span><span class="nv">for</span><span class="w"> </span><span class="nv">n</span><span class="o">=</span><span class="mi">3</span><span class="p">:</span><span class="w"> </span><span class="p">[(</span><span class="s">&#39;n b&#39;</span><span class="p">,</span><span class="w"> </span><span class="mi">382</span><span class="p">)]</span>
<span class="nf">Most</span><span class="w"> </span><span class="nv">common</span><span class="w"> </span><span class="nv">for</span><span class="w"> </span><span class="nv">n</span><span class="o">=</span><span class="mi">4</span><span class="p">:</span><span class="w"> </span><span class="p">[(</span><span class="s">&#39;n be&#39;</span><span class="p">,</span><span class="w"> </span><span class="mi">382</span><span class="p">)]</span>
<span class="nf">Most</span><span class="w"> </span><span class="nv">common</span><span class="w"> </span><span class="nv">for</span><span class="w"> </span><span class="nv">n</span><span class="o">=</span><span class="mi">5</span><span class="p">:</span><span class="w"> </span><span class="p">[(</span><span class="s">&#39;n ben&#39;</span><span class="p">,</span><span class="w"> </span><span class="mi">382</span><span class="p">)]</span>
<span class="nf">Most</span><span class="w"> </span><span class="nv">common</span><span class="w"> </span><span class="nv">for</span><span class="w"> </span><span class="nv">n</span><span class="o">=</span><span class="mi">6</span><span class="p">:</span><span class="w"> </span><span class="p">[(</span><span class="s">&#39;n benc&#39;</span><span class="p">,</span><span class="w"> </span><span class="mi">381</span><span class="p">)]</span>
</code></pre></div>

<p>Notice how different Process IDs (PIDs) start work simultaneously. If each task took 1 second, the total time would be roughly 1 second, not 4 seconds. This is a powerful hybrid strategy that combines a sequential algorithm with parallel execution.</p>
<h2 id="production-perspective_5">Production Perspective</h2>
<p><strong>Pattern: "Start simple, profile, then optimize the bottleneck."</strong>
This is a core philosophy in production engineering. You don't start with a complex hybrid model.
1.  You begin with the simplest possible solution (e.g., <code>sliding_window</code>).
2.  You deploy it and monitor its performance using tools like the benchmarks we built. This is called <strong>profiling</strong>.
3.  If‚Äîand only if‚Äîprofiling shows it's a performance bottleneck, you investigate <em>why</em>.
4.  You then implement a more sophisticated solution, like a hybrid dispatcher or a parallelized version, to target that specific bottleneck.</p>
<p>Hybrid approaches are powerful, but they add complexity. The code for our dispatcher and parallel runner is more complex than the simple <code>sliding_window</code> function. That complexity is a cost, and it should only be paid when there is a clear, measured performance benefit.</p>
<h2 id="production-considerations">Production Considerations</h2>
<h2 id="learning-objective_6">Learning Objective</h2>
<p>Apply algorithms effectively within the constraints of real-world software systems and teams.</p>
<h2 id="why-this-matters_6">Why This Matters</h2>
<p>An algorithm doesn't exist in a vacuum. It exists as part of a larger system, maintained by a team of engineers, and relied upon by users. The "best" algorithm isn't just about speed or memory; it's about balancing performance with maintainability, readability, and testability. This final piece of the puzzle is often what separates a good academic solution from a great production solution.</p>
<h2 id="core-production-tensions">Core Production Tensions</h2>
<h3 id="1-maintainability-vs-performance">1. Maintainability vs. Performance</h3>
<p>This is the central trade-off. Let's compare the code for our two most practical algorithms.</p>
<p><strong>Sliding Window</strong>:</p>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">find_repeats_sliding_window</span><span class="p">(</span><span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">n</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">collections</span><span class="o">.</span><span class="n">Counter</span><span class="p">:</span>
    <span class="n">counts</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">Counter</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">)</span> <span class="o">-</span> <span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">ngram</span> <span class="o">=</span> <span class="n">text</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">n</span><span class="p">]</span>
        <span class="n">counts</span><span class="p">[</span><span class="n">ngram</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">counts</span>
</code></pre></div>

<ul>
<li><strong>Readability</strong>: Extremely high. A junior developer could understand this in 30 seconds.</li>
<li><strong>Debuggability</strong>: Trivial. You can print <code>i</code> and <code>ngram</code> and see exactly what's happening.</li>
<li><strong>Performance</strong>: Good enough for small to medium texts.</li>
</ul>
<p><strong>Rolling Hash</strong>:</p>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">find_repeats_rolling_hash</span><span class="p">(</span><span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">n</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">collections</span><span class="o">.</span><span class="n">Counter</span><span class="p">:</span>
    <span class="c1"># ... setup for BASE, MOD, power ...</span>
    <span class="c1"># ... calculate initial hash ...</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">)</span> <span class="o">-</span> <span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">current_hash</span> <span class="o">=</span> <span class="p">(</span><span class="n">current_hash</span> <span class="o">-</span> <span class="nb">ord</span><span class="p">(</span><span class="n">text</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="o">*</span> <span class="n">power</span><span class="p">)</span> <span class="o">%</span> <span class="n">MOD</span>
        <span class="n">current_hash</span> <span class="o">=</span> <span class="p">(</span><span class="n">current_hash</span> <span class="o">*</span> <span class="n">BASE</span> <span class="o">+</span> <span class="nb">ord</span><span class="p">(</span><span class="n">text</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span> <span class="o">%</span> <span class="n">MOD</span>
        <span class="c1"># ... collision checking and storing ...</span>
    <span class="c1"># ... convert hashes back to ngrams ...</span>
    <span class="k">return</span> <span class="n">counts</span>
</code></pre></div>

<ul>
<li><strong>Readability</strong>: Lower. What are <code>BASE</code> and <code>MOD</code>? Why are we multiplying by <code>power</code>? This requires specialized knowledge of the algorithm.</li>
<li><strong>Debuggability</strong>: Harder. If you get the wrong count, is it a hash collision? An off-by-one in the loop? A bug in the modulus arithmetic?</li>
<li><strong>Performance</strong>: Excellent for large texts.</li>
</ul>
<p><strong>The Production Rule</strong>: "Your code will be read 10 times more often than it is written." A complex but performant piece of code imposes a tax on every future developer who has to touch it. Therefore, you should only choose the more complex solution if you have benchmark data that proves the simpler one is too slow for the business requirement.</p>
<h3 id="2-testing-strategies">2. Testing Strategies</h3>
<p>How do you ensure your algorithm is correct?
-   <strong>Unit Tests</strong>: Use small, known inputs. For example, test with <code>"banana"</code> and assert that the count of <code>"an"</code> is 2.
-   <strong>Edge Case Tests</strong>: What happens with an empty string? A string shorter than <code>n</code>? A string with Unicode characters?
-   <strong>Property-Based Tests</strong>: Instead of testing specific values, test the <em>properties</em> that should always be true. For example: "The sum of all n-gram counts should always be <code>(len(text) - n + 1)</code>."
-   <strong>Regression Tests</strong>: Once you find a bug, create a specific test case that fails with the bug and passes once it's fixed. This ensures the bug never reappears. In our benchmarks, we noticed the Suffix Array count was off by one. That's a perfect candidate for a regression test.</p>
<h3 id="3-monitoring-and-profiling">3. Monitoring and Profiling</h3>
<p>In a live system, you don't just deploy code and hope it's fast enough. You monitor it.
-   <strong>Timing Metrics</strong>: You'd wrap your function call to record its execution time. <code>start_time = time.time(); result = func(); duration = time.time() - start_time; log(duration)</code>.
-   <strong>Memory Metrics</strong>: You'd track the process's memory usage.
-   <strong>Alerting</strong>: If the average execution time for your function suddenly jumps by 50%, or memory usage spikes, an automated alert should be sent to the engineering team. This allows you to catch performance regressions before they impact many users.</p>
<p>This is essentially applying our benchmarking harness into a live production environment.</p>
<h3 id="4-team-considerations-the-bus-factor">4. Team Considerations (The "Bus Factor")</h3>
<p>The "bus factor" is a thought experiment: "How many people on your team could get hit by a bus before the project is in trouble?"</p>
<p>If you are the only person who understands the complex Suffix Array implementation with Kasai's algorithm, your team has a bus factor of 1. If you leave, no one can maintain that code.</p>
<p>This is a powerful argument for choosing simpler, more idiomatic code whenever possible. The "good enough" Sliding Window implementation has a much higher bus factor because any Python developer can understand and maintain it. A core responsibility of a senior engineer is to write code that <em>reduces</em> the bus factor, not increases it.</p>
<p><strong>The Final Mantra</strong>: "The most performant algorithm that is incomprehensible to your team is worse than a good-enough algorithm that everyone can help maintain."</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># Clean up the generated files at the end of the module</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Cleaning up generated text files...&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">file_name</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;small.txt&#39;</span><span class="p">,</span> <span class="s1">&#39;medium.txt&#39;</span><span class="p">,</span> <span class="s1">&#39;large.txt&#39;</span><span class="p">]:</span>
    <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">file_name</span><span class="p">):</span>
        <span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">file_name</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Removed </span><span class="si">{</span><span class="n">file_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Cleanup complete.&quot;</span><span class="p">)</span>
</code></pre></div>

<p><strong>Output</strong>:</p>
<div class="codehilite"><pre><span></span><code>Cleaning up generated text files...
Removed small.txt
Removed medium.txt
Removed large.txt
Cleanup complete.
</code></pre></div>

<h2 id="module-synthesis">Module Synthesis</h2>
<h2 id="module-5-synthesis-from-theory-to-practice">Module 5 Synthesis: From Theory to Practice</h2>
<p>This module shifted our focus from <em>how</em> algorithms work to <em>which</em> algorithm to use and <em>why</em>. This is one of the most important transitions in a developer's journey‚Äîmoving from a purely technical understanding to making strategic engineering decisions.</p>
<p>We established a four-part framework for this analysis:
1.  <strong>Benchmarking</strong>: We built a repeatable, fair system to measure time and memory, proving that you can't reason about performance without data.
2.  <strong>Scale Analysis</strong>: We saw how performance profiles change dramatically with input size. The "best" algorithm for 1KB of text was the worst for 5MB. Overhead dominates for small inputs, while asymptotic complexity dominates for large inputs.
3.  <strong>Decision Frameworks</strong>: We translated our benchmark results into a practical decision tree, a mental model for quickly selecting the right approach based on constraints like data size, memory, and latency requirements.
4.  <strong>Production Realities</strong>: We contextualized algorithm choice within a real-world engineering team, balancing raw performance against critical factors like code maintainability, testability, and team knowledge.</p>
<h3 id="looking-forward">Looking Forward</h3>
<p>You are now equipped not just to implement complex algorithms but to choose between them intelligently. You can justify your choice of a "simple" algorithm with data, and you know when to invest in a more complex solution because you understand the trade-offs.</p>
<p>In the final module, <strong>Module 6: Extensions and Real-World Applications</strong>, we will take these powerful tools and apply them to fascinating, large-scale problems. We'll move beyond abstract <code>n-gram</code> counting and see how these exact same algorithms power everything from plagiarism detection and DNA sequence analysis to real-time log monitoring. You have built the foundation; now it's time to see what you can build on top of it.</p>
        </div>
        <div class="footer">
            Generated on 2025-10-17 18:54:34 | Made with ‚ù§Ô∏è by GitHub Pages Generator
        </div>
    </div>
    <script>
        // Syntax highlighting for code blocks
        document.addEventListener('DOMContentLoaded', (event) => {
            document.querySelectorAll('pre code').forEach((block) => {
                hljs.highlightElement(block);
            });
        });
    </script>
</body>
</html>